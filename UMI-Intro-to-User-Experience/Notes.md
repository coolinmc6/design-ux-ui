<a name='top'></a>
# Introduction to User Experience



## Part 1: What is UX? What are UX Research and Design?

### L1: What is User Experience?

- What is Good UX?
	+ usefule
	+ helpful
	+ easy to learn
	+ accessible
	+ attractive
	+ fun
	+ connected
	+ delightful
- What is a Bad UX?
	+ Stressful
	+ Confusing
	+ Ugly
	+ Distracting
	+ Inefficient
	+ Tedious
	+ Condescending
	+ Inconsiderate
	+ Frustrating
- Why does it matter?
	+ A successful experience is the overlap of "what users want to do" and "what you want your users to do"
- The Whole User Experience
	+ UX = the experience people have when they interact with your product
		* using the product
		* choosing the product
		* acquiring the product
		* learning how to use the product
		* fixing the product
		* upgrading the product
		* etc.
- Why is UX hard?
	+ You are not the user?
		* you don't represent ALL users
	+ Computers are *weird*
		* translating what is easy for computers into something that is easy for humans
	+ Software is (usually) complex
- How to Make UX Easy
	+ Follow an interative prototyping process
	+ Apply user-centered research and design methods
	+ Understand a bit about human behavior
	+ Apply common sense

[back to top](#top)

### L2: The UX Process

- How to Make UX Easy
	+ Follow an interative prototyping process
	+ Apply user-centered research and design methods
	+ Understand a bit about human behavior
	+ Apply common sense
- Fail Fast
	+ you won't get it right 
	+ get it wrong quickly and as often as possilbe
+ Assess => Design => Build => Assess (again) and so on
	* circular
	- the "Spiral Model" 
	- UX Research in the "Assess" phase
	- UX Design in the "Design" phase
* Key Methods: UX Research
	- Interviews
	- Observations
	- Surveys
	- User Testing
	- Inspection Methods
* Key Methods: UX Design
	- Personas, Scenarios, User Stories
	- Sketching and Ideation
	- Storyboarding
	- Mapping and Navigation Design
	- Comparative Research
	- Lo-, Mid-, and Hi-Fidelity Prototyping
* Understand How People Work
	- What can people perceive?
		+ how do they extract information from visual stimuli
	- How do people do things?
	- How does emotion play a role?
* Common Sense

[back to top](#top)

### L3: Components of UX

- Good and Bad UX
- Components of UX
	+ Value, Usability, Adoptability, Desirability
	+ Value
	+ Usability
		* can users do what they need to do?
	+ Desirability
		* Is it fun, attractive and pleasant to use?
	+ Adoptability
		* How easy is it to start using the device?
		* example: DuoLingo => start learning right away.
- Assessing UX: Questions
	+ Value
		* What do users need?
		* Does this design fulfill the need?
	+ Usability
		* How do they do it now?
- UX is not just about usability, attractiveness, etc.
- Let the process be your guide; ask questions and iterate
- **Homework:**
	+ Discuss 1 example of good UX and 1 example of bad UX. Answer these questions:
		+ What was your goal of using the interface?
		+ What action did you intend to perform?
		+ What features of the interface made it easy or difficult to perform the action?
		+ How would you make it better if it was a bad design?


[back to top](#top)

## Part 2: UX Research Overview - Part 1

### L4: Basic Methods of UX Research

- Three basic methods of UX Research
	+ Ask
	+ Observe
	+ Inspect
- Ask
	+ interviews
	+ surveys
		* questions distributed to focus groups, diary studies, experience sampling
- Observe
	+ Ethnographic obsesrvations
	+ User testing
		* ask them to perform specific tasks to see how they use the product
	+ Usage Analytics
		* analyze large scale traces of system usage
- Inspection Methods
	+ guideline-based
	+ Walkthroughs
	+ Comparative Analysis
- Combo: Watch and Ask
	+ User testing
	+ Contextual Interviews
		* ask questions while observing "natural" activities
- When to use What?
	+ Ask when:
		* observation is infeasible (infrequent, long, private)
		* values and motivations are key
		* (Surveys) Large numbers and high certainty are needed
	+ Observer when:
		* Self-report will miss information (memory, tacit knowledge)
		* Process and communication are important
		* (Analytics) Large numbres and high certainty are needed
	+ Inspect when:
		* you have a product to inspect

### L5: User Testing, Part 1

- What is User Testing
	+ Watch representative users try to accomplish importants tasks using a product
	+ AKA "usability testing" 
- Why User Testing?
	+ You learn a LOT from watching people use a system
		* What works and what doesn't
		* Why things work and don't
		* User needs you missed
	+ Why not just use your own experience?
		* You know too much about the sytem, AND...
		* You know too little the users and their thinking
- Basic Idea
	+ Find potential users
	+ Ask them to do some stuff
	+ Observe
	+ Ask some questions (debrief)
	+ Write down what you learned
- Potential Users
	+ People who fall within the target audience
		* attitudes
		* behaviors
		* characteristics
	+ NOT current users
		* OK if current users of the system but not for selected tasks
- Tasks (what you ask them to do)
	+ i.e. for Amazon
		* buy a coffee maker
		* write a book review
- Choosing tasks
	+ pick taks that most users need to do
	+ Close-ended tasks
		* have a clear end point
		* have a verifiable outcome
		* Often has an expected path
	+ Open-ended Tasks
		* Allow user to judge when complete
		* May not be verifiable
		* Allow following alternate paths
		* Examples:
			- find some books that you might like to read on vacation
			- CM: find some skills that you'd like to learn
+ Which are Better?
	* Close-Ended
		- less natural
		- control for motivation
		- control for interpretation
		- Assess for success
	* Open-Ended
		- More natural
		- varying motivation
		- Varying interpretation
		- Success is unknown
	* You can use both!! 
	* Maybe use close-ended tasks initially to see that people can use it
+ Task Sets
	* Progress from easier to harder
	* Cover a range of critical task types (browse, search, buy)
	* Can include open and close-ended tasks
	* be careful to avoid "ordering effects"
		- if your tasks are set in a sequential or quasi-sequential order, they'd have help doing something that they normally wouldn't have
	* 


### L6: User Testing, Part 2

- Task Wording
	+ don't lead the witness
		* Not good: "Put three books in your shopping cart and buy them using standard shipping"
		* Better: "Choose three books and buy them"
	+ Avoid ambiguity
		* Not good: "Use a list to find a gift for your 10-year old nephew"
		* Better: "A friend told you about Amazon's list feature. Use an Amazon list"
	+ Include context and motivation
		* Not good: "Buy a book and have it shipped by Monday"
		* Better: "Colleagues from Japan are coming into town and you need a book on Japanese business practices by Monday to brush up on business etiquette"
	+ Pilot Test
		* it's very hard to get right on the first try
		* Try the tasks out
			- Yourself!!
			- with a friend or two
- Think Aloud
	+ participants to say (out loud) what they are thinking
	+ Thinking includes
		* looking for something
		* Reading text (have them read aloud)
		* Hypothesizing about how the system might work
		* Interpreting system options
		* Interpreting system feedback
		* Explaining decisions
		* Feeling frustrated, happy
	+ Advantages
		* hear how the user thinks about the task
		* learn what the user actually sees and notices
		* hear how the user interprets options, feedback
	+ Disadvantages
		* timing will not be realistic
		* attention to detail will not be quite realistic
		* need to determine "rules of engagement" for questions, mistakes, etc.
			- are you not going to act like a normal person and just NOT answer them? State that up front
- 

### L7: User Testing, Part 3

- Debrief (after tasks)
	+ Review problems, get more information
	+ Ask about usefulness, value
	+ Ask about perceived usability, aesthetics, credibility
	+ compare to known alternatives
- Making Sense of the Test
	+ Capture "critical incidents"
		* errors
		* expressions of frustration
		* breakdowns
			- something took a really long time but should've been quick
			- roundabout processes
		* pleasant surprises
	+ Assess success/failure
		* usually a spectrum
	+ Capture overall reaction & reaction to specific aspects
	+ Link incidents, success/failure, and subjective reaction
- Learning from the Test
	+ Quick! Write it down!
	+ Critical Incidents and WHY they happened
		* mental model mismatches
		* misinterpretations
		* invalid assumptions made by the system
		* missing user needs
		* too little flexibility
		* too little guidance
	+ Here are some more high-level questions for them?
		* What is your overall impression of *the product*?
		* Do you think that *the product* would be useful for you, personally? Why or why not?
		* If no: who do you think it would be useful for? Why?
		* What do you like best about *the product*?
		* What do you think needs to be improved?
	+ Follow-up with some questions about the specific product that is relevant to THEM as a person. Here is an example of some of those questions using Doodle as the product:
		* How often do you schedule meetings with other people?
		* How do you usually go about scheduling such meetings?
		* Have you ever used any sites or apps that you think are similar to Doodle? Which ones, and how much experience have you had with them?
		* How many hours per week would you estimate that you spend online?
	+ Problems => Severity: impact on...
		* success/failure
			- did the problems affect the success or failure of the task? Some problems are show-stoppers and others are not
		* subjective experience
			- how did they problems affect their experience? Did it completely ruin it?
		* product goals
			- did they use the product in a different way than you expected?
	+ Other UX factors
		* usefulness
		* desirability
		* credibility
	+ Wrap up your de-brief with a summary of the following items:
		* Participants: who they were / kind of users they were
		* Basic Results: how well did the test go, did they succeed? Did all participants succeed? Any partial or complete failures?
		* Findings and Recommendations:
			- report major problems and try to diagnose the causes
			- Focus on the few significant observations, not a long list of minor things
			- What worked well? What didn't? What were the most confusing / frustrating parts?
			- Support findings with your EVIDENCE
- One Other VERY IMPORTANT Thing
	+ participation is voluntary
	+ participants can stop at any time
	+ you are testing the system, not the participant
	+ you need to let the participants know this
		* make them feel comfortable! The system is being tested, which means that they're struggles are really the struggles of the system
- What's "Micro" About This?
	+ relaxed recruiting
		* people close enough to target audience to be able to imagine
		* A.K.A. "Hallway" usability test
	+ Fewer tasks
		* < 30 minutes rather than 60-90 minutes
	+ Little or no data collection
		* no recording
		* no questionnaires
		* no logging
	+ Off-the-cuff analysis

- For the assignment, I need to prepare two test scripts (or one script with two versions):
	+ Moderator Script - one for MY reference with the tasks, my notes and tips, etc.
	+ Participant Script - this contains ONLY the tasks to be shared with the participant
- Make sure the assignments are timed; you don't have to rush through them
- Debrief
	+ write down your notes about their performance



[back to top](#top)

## Part 3: UX Research Overview - Part 2

[back to top](#top)

## Part 4: UX Design Overview - Part 1

[back to top](#top)

## Part 5: UX Design Overview - Part 2


[back to top](#top)






































